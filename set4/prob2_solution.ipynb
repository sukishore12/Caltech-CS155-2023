{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNmjmydtlM55f9gJRj0v3cO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/emiletimothy/Caltech-CS155-2023/blob/main/set4/prob2_solution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0fzZb8grE78U"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Setup"
      ],
      "metadata": {
        "id": "aICcIvNtNGk2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = nn.Sequential(nn.Linear(9, 5),\n",
        "                    nn.Linear(5, 2),\n",
        "                    nn.Softmax(dim=1))\n",
        "\n",
        "print(model)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "# binary classification problem, so BCELoss is the best choice\n",
        "loss_fn = nn.BCELoss()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qtMSBKxdFfjq",
        "outputId": "47e8d089-01a8-4478-bd5e-22008b917fd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequential(\n",
            "  (0): Linear(in_features=9, out_features=5, bias=True)\n",
            "  (1): Linear(in_features=5, out_features=2, bias=True)\n",
            "  (2): Softmax(dim=1)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Setup"
      ],
      "metadata": {
        "id": "VvPFMow_NNry"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# data preprocessing\n",
        "\n",
        "\n",
        "df = pd.read_csv(\"COVID-19_Case_Surveillance_Public_Use_Data_Subset.csv\")\n",
        "\n",
        "# only need rows with non-missing target value\n",
        "df = df[df[\"death_yn\"].isin([\"Yes\", \"No\"])]\n",
        "\n",
        "# don't need cols with majority missing values\n",
        "df = df.drop(['icu_yn', 'medcond_yn'], axis=1)\n",
        "\n",
        "# date rows into numeric form\n",
        "date_cols = ['cdc_case_earliest_dt ', 'cdc_report_dt', 'pos_spec_dt', 'onset_dt']\n",
        "for date_col in date_cols:\n",
        "    df[date_col] = pd.to_datetime(df[date_col], infer_datetime_format=True).astype('int64')\n",
        "    df[date_col] = df[date_col]  / df[date_col].abs().max()\n",
        "\n",
        "# factorize categorical columns \n",
        "cat_cols = ['current_status', 'sex', 'age_group', 'race_ethnicity_combined', 'hosp_yn', 'death_yn']\n",
        "for cat_col in cat_cols:\n",
        "    df[cat_col] = pd.factorize(df[cat_col])[0]\n",
        "\n",
        "# shuffle dataset\n",
        "df = df.sample(frac=1)\n",
        "\n",
        "# sanity check\n",
        "df.describe()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "id": "7m_kQfspQJNf",
        "outputId": "1df38e7b-5802-42b2-e917-7326ee5b0c34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-ad4f9dcaae31>:15: FutureWarning: casting datetime64[ns] values to int64 with .astype(...) is deprecated and will raise in a future version. Use .view(...) instead.\n",
            "  df[date_col] = pd.to_datetime(df[date_col], infer_datetime_format=True).astype('int64')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          Unnamed: 0  cdc_case_earliest_dt   cdc_report_dt    pos_spec_dt  \\\n",
              "count  259715.000000          259715.000000  259715.000000  259715.000000   \n",
              "mean   400254.108196               0.973826       0.976256      -1.757605   \n",
              "std    230797.097038               0.012740       0.012037       3.203803   \n",
              "min         0.000000               0.943529       0.943564      -5.514334   \n",
              "25%    200866.000000               0.962284       0.965302      -5.514334   \n",
              "50%    400311.000000               0.975924       0.979346       0.959709   \n",
              "75%    600097.500000               0.982227       0.983580       0.980319   \n",
              "max    799996.000000               1.000000       1.000000       1.000000   \n",
              "\n",
              "            onset_dt  current_status            sex      age_group  \\\n",
              "count  259715.000000   259715.000000  259715.000000  259715.000000   \n",
              "mean       -2.495756        0.164754       0.555351       3.376998   \n",
              "std         3.235140        0.370959       0.552555       2.096839   \n",
              "min        -5.515474        0.000000       0.000000       0.000000   \n",
              "25%        -5.515474        0.000000       0.000000       2.000000   \n",
              "50%        -5.515474        0.000000       1.000000       3.000000   \n",
              "75%         0.966262        0.000000       1.000000       5.000000   \n",
              "max         1.000000        1.000000       3.000000       9.000000   \n",
              "\n",
              "       race_ethnicity_combined        hosp_yn       death_yn  \n",
              "count            259715.000000  259715.000000  259715.000000  \n",
              "mean                  1.771915       0.707787       0.026159  \n",
              "std                   1.273895       0.959862       0.159610  \n",
              "min                   0.000000       0.000000       0.000000  \n",
              "25%                   1.000000       0.000000       0.000000  \n",
              "50%                   1.000000       0.000000       0.000000  \n",
              "75%                   3.000000       2.000000       0.000000  \n",
              "max                   8.000000       3.000000       1.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3014a32a-fa90-4b63-9930-e97ef8910720\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>cdc_case_earliest_dt</th>\n",
              "      <th>cdc_report_dt</th>\n",
              "      <th>pos_spec_dt</th>\n",
              "      <th>onset_dt</th>\n",
              "      <th>current_status</th>\n",
              "      <th>sex</th>\n",
              "      <th>age_group</th>\n",
              "      <th>race_ethnicity_combined</th>\n",
              "      <th>hosp_yn</th>\n",
              "      <th>death_yn</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>259715.000000</td>\n",
              "      <td>259715.000000</td>\n",
              "      <td>259715.000000</td>\n",
              "      <td>259715.000000</td>\n",
              "      <td>259715.000000</td>\n",
              "      <td>259715.000000</td>\n",
              "      <td>259715.000000</td>\n",
              "      <td>259715.000000</td>\n",
              "      <td>259715.000000</td>\n",
              "      <td>259715.000000</td>\n",
              "      <td>259715.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>400254.108196</td>\n",
              "      <td>0.973826</td>\n",
              "      <td>0.976256</td>\n",
              "      <td>-1.757605</td>\n",
              "      <td>-2.495756</td>\n",
              "      <td>0.164754</td>\n",
              "      <td>0.555351</td>\n",
              "      <td>3.376998</td>\n",
              "      <td>1.771915</td>\n",
              "      <td>0.707787</td>\n",
              "      <td>0.026159</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>230797.097038</td>\n",
              "      <td>0.012740</td>\n",
              "      <td>0.012037</td>\n",
              "      <td>3.203803</td>\n",
              "      <td>3.235140</td>\n",
              "      <td>0.370959</td>\n",
              "      <td>0.552555</td>\n",
              "      <td>2.096839</td>\n",
              "      <td>1.273895</td>\n",
              "      <td>0.959862</td>\n",
              "      <td>0.159610</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.943529</td>\n",
              "      <td>0.943564</td>\n",
              "      <td>-5.514334</td>\n",
              "      <td>-5.515474</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>200866.000000</td>\n",
              "      <td>0.962284</td>\n",
              "      <td>0.965302</td>\n",
              "      <td>-5.514334</td>\n",
              "      <td>-5.515474</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>400311.000000</td>\n",
              "      <td>0.975924</td>\n",
              "      <td>0.979346</td>\n",
              "      <td>0.959709</td>\n",
              "      <td>-5.515474</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>600097.500000</td>\n",
              "      <td>0.982227</td>\n",
              "      <td>0.983580</td>\n",
              "      <td>0.980319</td>\n",
              "      <td>0.966262</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>799996.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3014a32a-fa90-4b63-9930-e97ef8910720')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3014a32a-fa90-4b63-9930-e97ef8910720 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3014a32a-fa90-4b63-9930-e97ef8910720');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# accounting for data imbalance\n",
        "\n",
        "# separate data set aside for training\n",
        "train_df = df.iloc[:220892]\n",
        "\n",
        "# separate training data into classifications\n",
        "train_df_1 = train_df[train_df[\"death_yn\"] == 1]\n",
        "train_df_0 = train_df[train_df[\"death_yn\"] == 0]\n",
        "\n",
        "# recombine with a much smaller proportion of 0 death_yn rows\n",
        "# leaving a 1:5 data imbalance instead of ~98:2\n",
        "train_df = pd.concat([train_df_1, train_df_0.iloc[:len(train_df_1) * 5]])\n",
        "\n",
        "# shuffle again\n",
        "train_df = train_df.sample(frac=1)\n",
        "\n",
        "X = train_df.drop(['death_yn', 'Unnamed: 0'], axis=1)\n",
        "y = train_df['death_yn']\n",
        "\n",
        "print(len(X))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CkAd6rEb2ltY",
        "outputId": "850478a2-a7f8-42c5-fd71-d1095a3b72f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34410\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# do not balance testing data\n",
        "Xt = df.drop(['death_yn', 'Unnamed: 0'], axis=1).iloc[220892:]\n",
        "yt = df['death_yn'].iloc[220892:]\n",
        "\n",
        "# making into torch tensors\n",
        "\n",
        "X_tensor = torch.from_numpy(X.values).float()\n",
        "Xt_tensor = torch.from_numpy(Xt.values).float()\n",
        "\n",
        "y_tensor = F.one_hot(torch.from_numpy(y.values)).float()\n",
        "yt_tensor = F.one_hot(torch.from_numpy(yt.values)).float()\n",
        "\n",
        "# make datasets and dataloaders\n",
        "\n",
        "train_dataset = TensorDataset(X_tensor, y_tensor)\n",
        "test_dataset = TensorDataset(Xt_tensor, yt_tensor)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=True) \n"
      ],
      "metadata": {
        "id": "3Wn-AQp6FDpM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Loop"
      ],
      "metadata": {
        "id": "uKl5Tm2TNXxc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Some layers, such as Dropout, behave differently during training\n",
        "model.train()\n",
        "\n",
        "for epoch in range(20):\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        # Erase accumulated gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        output = model(data)\n",
        "\n",
        "        # Calculate loss\n",
        "        loss = loss_fn(output, target)\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "        \n",
        "        # Weight update\n",
        "        optimizer.step()\n",
        "\n",
        "        break\n",
        "\n",
        "    # Track loss each epoch\n",
        "    print('Train Epoch: %d  Loss: %.4f' % (epoch + 1,  loss.item()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-RVMsj0NaN7",
        "outputId": "4862824a-2b87-42ba-b1ae-545b3d156f03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 1  Loss: 0.5341\n",
            "Train Epoch: 2  Loss: 0.6181\n",
            "Train Epoch: 3  Loss: 0.5594\n",
            "Train Epoch: 4  Loss: 0.3565\n",
            "Train Epoch: 5  Loss: 0.2558\n",
            "Train Epoch: 6  Loss: 0.2941\n",
            "Train Epoch: 7  Loss: 0.4341\n",
            "Train Epoch: 8  Loss: 0.6242\n",
            "Train Epoch: 9  Loss: 0.3733\n",
            "Train Epoch: 10  Loss: 0.4663\n",
            "Train Epoch: 11  Loss: 0.6345\n",
            "Train Epoch: 12  Loss: 0.3277\n",
            "Train Epoch: 13  Loss: 0.4517\n",
            "Train Epoch: 14  Loss: 0.3253\n",
            "Train Epoch: 15  Loss: 0.6741\n",
            "Train Epoch: 16  Loss: 0.5799\n",
            "Train Epoch: 17  Loss: 0.5828\n",
            "Train Epoch: 18  Loss: 0.5329\n",
            "Train Epoch: 19  Loss: 0.3256\n",
            "Train Epoch: 20  Loss: 0.4280\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing Loop"
      ],
      "metadata": {
        "id": "YZCNGh5mNbE0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Putting layers like Dropout into evaluation mode\n",
        "model.eval()\n",
        "\n",
        "test_loss = 0\n",
        "correct = 0\n",
        "\n",
        "# Turning off automatic differentiation\n",
        "with torch.no_grad():\n",
        "    for data, target in test_loader:\n",
        "        output = model(data)\n",
        "        test_loss += loss_fn(output.squeeze(), target.squeeze()).item()  # Sum up batch loss\n",
        "        pred = output.argmax(dim=1, keepdim=False)  # Get the index of the max class score\n",
        "        correct += pred.eq(target.argmax(dim=1, keepdim=False).view_as(pred)).sum().item()\n",
        "\n",
        "test_loss /= len(test_loader.dataset)\n",
        "\n",
        "print('Test set: Average loss: %.4f, Accuracy: %d/%d (%.4f)' %\n",
        "      (test_loss, correct, len(test_loader.dataset),\n",
        "       100. * correct / len(test_loader.dataset)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2SxnJ3eHNfgb",
        "outputId": "83fc1bb0-5d38-4c08-f586-64d71caac436"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set: Average loss: 0.0080, Accuracy: 37764/38823 (97.2722)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Weight Matrix Visualization"
      ],
      "metadata": {
        "id": "sf9UHC-kZ25f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "weights = model.state_dict()['0.weight']\n",
        "\n",
        "sns.heatmap(weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "aBXDC10mRNto",
        "outputId": "ff31fc40-d9e7-48f1-e92e-57988b803d31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f4c8b6ce610>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2-Layer Linear Model"
      ],
      "metadata": {
        "id": "91H6-NUVZ8Gd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ZKIg19ZX0P04"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = nn.Sequential(nn.Linear(9, 5),\n",
        "                       nn.Linear(5, 5),\n",
        "                       nn.Linear(5, 2),\n",
        "                       nn.Softmax(dim=1))\n",
        "\n",
        "optimizer2 = torch.optim.Adam(model2.parameters(), lr=1e-3)\n",
        "\n",
        "print(model2)\n",
        "\n",
        "# Same training and testing loops\n",
        "model2.train()\n",
        "for epoch in range(20):\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        optimizer2.zero_grad()\n",
        "        output = model2(data)\n",
        "        loss = loss_fn(output, target)\n",
        "        loss.backward()\n",
        "        optimizer2.step()\n",
        "\n",
        "    print('Train Epoch: %d  Loss: %.4f' % (epoch + 1,  loss.item()))\n",
        "\n",
        "model2.eval()\n",
        "\n",
        "test_loss = 0\n",
        "correct = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for data, target in test_loader:\n",
        "        output = model2(data)\n",
        "        test_loss += loss_fn(output.squeeze(), target).item()  # Sum up batch loss\n",
        "        pred = output.argmax(dim=1, keepdim=True)  # Get the index of the max class score\n",
        "        correct += pred.eq(target.argmax(dim=1, keepdim=True).view_as(pred)).sum().item()\n",
        "\n",
        "test_loss /= len(test_loader.dataset)\n",
        "\n",
        "print('Test set: Average loss: %.4f, Accuracy: %d/%d (%.4f)' %\n",
        "      (test_loss, correct, len(test_loader.dataset),\n",
        "       100. * correct / len(test_loader.dataset)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SUd6CAB-WebM",
        "outputId": "d249361a-3110-4e53-b86b-78b70cce132e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequential(\n",
            "  (0): Linear(in_features=9, out_features=5, bias=True)\n",
            "  (1): Linear(in_features=5, out_features=5, bias=True)\n",
            "  (2): Linear(in_features=5, out_features=2, bias=True)\n",
            "  (3): Softmax(dim=1)\n",
            ")\n",
            "Train Epoch: 1  Loss: 0.4641\n",
            "Train Epoch: 2  Loss: 0.8944\n",
            "Train Epoch: 3  Loss: 0.4328\n",
            "Train Epoch: 4  Loss: 0.3761\n",
            "Train Epoch: 5  Loss: 0.2581\n",
            "Train Epoch: 6  Loss: 0.0712\n",
            "Train Epoch: 7  Loss: 0.3082\n",
            "Train Epoch: 8  Loss: 0.4761\n",
            "Train Epoch: 9  Loss: 0.1783\n",
            "Train Epoch: 10  Loss: 0.2534\n",
            "Train Epoch: 11  Loss: 0.1623\n",
            "Train Epoch: 12  Loss: 0.3572\n",
            "Train Epoch: 13  Loss: 0.2141\n",
            "Train Epoch: 14  Loss: 0.4104\n",
            "Train Epoch: 15  Loss: 0.4796\n",
            "Train Epoch: 16  Loss: 0.1172\n",
            "Train Epoch: 17  Loss: 0.4619\n",
            "Train Epoch: 18  Loss: 0.1892\n",
            "Train Epoch: 19  Loss: 0.1924\n",
            "Train Epoch: 20  Loss: 0.2723\n",
            "Test set: Average loss: 0.0050, Accuracy: 37078/38823 (95.5052)\n"
          ]
        }
      ]
    }
  ]
}